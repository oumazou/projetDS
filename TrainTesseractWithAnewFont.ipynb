{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TrainTesseractWithAnewFont.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiFG5vFZQDZl"
      },
      "source": [
        "#**DOWNLOAD THESE REQUIRED FILES FROM TESSERACT GITHUB PAGE**\n",
        "\n",
        "Download these required files from github and upload to **Google Drive** \n",
        "\n",
        "***1. Tesseract 4.1*** :-\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "https://github.com/tesseract-ocr/tesseract/tree/4.1\n",
        "\n",
        "***2. Download any TRAINEDDATA***\n",
        "\n",
        "https://github.com/tesseract-ocr/tessdata_best\n",
        "\n",
        "\n",
        "\n",
        "You just have to download one trained data.\n",
        "for example **eng.traineddata** , if you want to train for English language.\n",
        "\n",
        "** ▶ important ◀**\n",
        "\n",
        "---\n",
        "\n",
        "After downloading it , put **eng.traineddata** inside the downloaded tesseract folder **tesseract/tessdata**\n",
        "\n",
        "***3. Langdata lstm*** :-\n",
        "\n",
        "---\n",
        "\n",
        "https://github.com/tesseract-ocr/langdata_lstm\n",
        "\n",
        "***The size of the file is too big.*** you dont have to download the whole directory.\n",
        "You just have to download only some important directory.\n",
        "So download this chrome extension extension. This will allow you to select and download specific directory and files.\n",
        "\n",
        "https://chrome.google.com/webstore/detail/gitzip-for-github/ffabmkklhbepgcgfonabamgnfafbdlkn\n",
        "\n",
        "\n",
        "***IMPORTANT FOLDER AND FILES TO DOWNLOAD FROM LANGDATA LSTM ***\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "1. Specific language Code folder , for example **'eng'** folder for english\n",
        "2. **Licence**\n",
        "3. **desired_bigrams.txt**\n",
        "4. **font_properties**\n",
        "5. **radical-stroke.txt**\n",
        "6. **forbidden_characters_default**\n",
        "7. In some case you also need to download **Latin.unicharset** and **Latin.xheights** , Other wise it will throw some errors.\n",
        "\n",
        "FOLDER STRUCTURE ▶\n",
        "\n",
        "    ------tesseract\n",
        "    |         |----tessdata\n",
        "    |                |---eng.traineddata\n",
        "    |\n",
        "    ------langdata_lstm\n",
        "\n",
        "\n",
        "\n",
        "FINALLY , UPLOAD EVERYTHING TO ***GOOGLE DRIVE*** ROOT FOLDER\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1j5KIFyiHABY"
      },
      "source": [
        "\n",
        "\n",
        "#**#1 INSTALL TESSERACT**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zGWFQbcLXhc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f83a34dc-db54-4b5a-f623-f4ecfdc70049"
      },
      "source": [
        "!sudo apt install tesseract-ocr"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 4,795 kB of archives.\n",
            "After this operation, 15.8 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-eng all 4.00~git24-0e00fe6-1.2 [1,588 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-osd all 4.00~git24-0e00fe6-1.2 [2,989 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr amd64 4.00~git2288-10f4998a-2 [218 kB]\n",
            "Fetched 4,795 kB in 0s (11.9 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 156210 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_4.00~git24-0e00fe6-1.2_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (4.00~git24-0e00fe6-1.2) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_4.00~git24-0e00fe6-1.2_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (4.00~git24-0e00fe6-1.2) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.00~git2288-10f4998a-2_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.00~git2288-10f4998a-2) ...\n",
            "Setting up tesseract-ocr-osd (4.00~git24-0e00fe6-1.2) ...\n",
            "Setting up tesseract-ocr-eng (4.00~git24-0e00fe6-1.2) ...\n",
            "Setting up tesseract-ocr (4.00~git2288-10f4998a-2) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egfJBI0-HOd2"
      },
      "source": [
        "#**#2 CREATE FOLDERS**\n",
        "\n",
        "---\n",
        "**fonts**   ▶    &nbsp;&nbsp;&nbsp; fonts to be uploaded <br>\n",
        "**train**   ▶    &nbsp;&nbsp;&nbsp;&nbsp; Data for training to be generated<br>\n",
        "**output**  ▶    &nbsp; Output of trained data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWmLuBbVNDpD"
      },
      "source": [
        "!mkdir fonts output train"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sq9Nqpa59fuQ"
      },
      "source": [
        "#**#3 UPLOAD YOUR FONT IN FONTS DIRECTORY**\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mztdS2jPEPd2"
      },
      "source": [
        "#**#4 GET YOUR FONT NAME**\n",
        "\n",
        "---\n",
        "**Double click on .ttf file to see the font name**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-to899PuG2RM"
      },
      "source": [
        "#**#5 ASSIGN IT**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4WaQNdvEbzp"
      },
      "source": [
        "font_name = 'ShelbyCursive Medium'  #@param {type: \"string\"}\n",
        "font_name2 = 'BrownBagLunch Medium'  #@param {type: \"string\"}\n",
        "font_name3 = 'Daniel'  #@param {type: \"string\"}\n",
        "font_name_number = 'Number letter'  #@param {type: \"string\"}\n",
        "font_name_number2 = 'Give You Glory'  #@param {type: \"string\"}\n",
        "font_name_number3 = 'Rock Salt'  #@param {type: \"string\"}\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2WGcBOwJl0k"
      },
      "source": [
        "#**#6 ADD GOOGLE DRIVE**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8w_sAtrpgVL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7f86aa2-5803-48a6-e35e-112caf091da3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cZRk02wHf3F"
      },
      "source": [
        "#**#6 CHANGE PERMISSION OF TESSERACT FOLDER**\n",
        "\n",
        "---\n",
        "**Run this change the permission of tesseract folder.**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMMTbc-xsXzI"
      },
      "source": [
        "!chmod 755 -R /content/drive/MyDrive/tesseract/src/training/tesstrain.sh"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlDBON6ulWkC"
      },
      "source": [
        "#**#7 EXTRACT 'eng.lstm' FROM 'eng.traineddata'**\n",
        "\n",
        "**'eng.lstm' data will be generated from 'eng.taineddata' , which will we use for further fine tuning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ackgGjeexk0o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3678837d-cafa-46ee-9667-2a39324da4f7"
      },
      "source": [
        "!combine_tessdata -e /content/drive/MyDrive/tesseract/tessdata/eng.traineddata eng.lstm"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting tessdata components from /content/drive/MyDrive/tesseract/tessdata/eng.traineddata\n",
            "Wrote eng.lstm\n",
            "Version string:4.00.00alpha:eng:synth20170629:[1,36,0,1Ct3,3,16Mp3,3Lfys64Lfx96Lrx96Lfx512O1c1]\n",
            "17:lstm:size=11689099, offset=192\n",
            "18:lstm-punc-dawg:size=4322, offset=11689291\n",
            "19:lstm-word-dawg:size=3694794, offset=11693613\n",
            "20:lstm-number-dawg:size=4738, offset=15388407\n",
            "21:lstm-unicharset:size=6360, offset=15393145\n",
            "22:lstm-recoder:size=1012, offset=15399505\n",
            "23:version:size=80, offset=15400517\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9WozFAJkhUT"
      },
      "source": [
        "#**#8 GENERATE TRAINING DATA**\n",
        "\n",
        "**The training data will be generates inside the 'train' folder.**\n",
        "\n",
        "Change Max pages as per your need. The default here is 10. Increase this value to get less error.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Idoqy3pLnuWa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32c3cf09-574e-42ec-9715-8503791b4553"
      },
      "source": [
        "\n",
        "\n",
        "!rm -rf train/*\n",
        "! /content/drive/MyDrive/tesseract/src/training/tesstrain.sh --fonts_dir fonts \\\n",
        "\t--fontlist '{font_name_number3}' \\\n",
        "\t--lang eng \\\n",
        "\t--linedata_only \\\n",
        "\t--langdata_dir /content/drive/MyDrive/langdata_lstm \\\n",
        "\t--tessdata_dir /content/drive/MyDrive/tesseract/tessdata \\\n",
        "\t--save_box_tiff \\\n",
        "\t--maxpages 10 \\\n",
        "\t--output_dir train\n",
        " \n",
        "\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Starting training for language 'eng'\n",
            "[Sat Mar 26 17:12:20 UTC 2022] /usr/bin/text2image --fonts_dir=fonts --ptsize 12 --font=Rock Salt --outputbase=/tmp/font_tmp.h2pBxkz0mZ/sample_text.txt --text=/tmp/font_tmp.h2pBxkz0mZ/sample_text.txt --fontconfig_tmpdir=/tmp/font_tmp.h2pBxkz0mZ\n",
            "Rendered page 0 to file /tmp/font_tmp.h2pBxkz0mZ/sample_text.txt.tif\n",
            "\n",
            "=== Phase I: Generating training images ===\n",
            "Rendering using Rock Salt\n",
            "[Sat Mar 26 17:12:22 UTC 2022] /usr/bin/text2image --fontconfig_tmpdir=/tmp/font_tmp.h2pBxkz0mZ --fonts_dir=fonts --strip_unrenderable_words --leading=32 --xsize=3600 --char_spacing=0.0 --exposure=0 --outputbase=/tmp/eng-2022-03-26.f32/eng.Rock_Salt.exp0 --max_pages=10 --font=Rock Salt --ptsize 12 --text=/content/drive/MyDrive/langdata_lstm/eng/eng.training_text\n",
            "Stripped 2 unrenderable words\n",
            "Rendered page 0 to file /tmp/eng-2022-03-26.f32/eng.Rock_Salt.exp0.tif\n",
            "Stripped 4 unrenderable words\n",
            "Rendered page 1 to file /tmp/eng-2022-03-26.f32/eng.Rock_Salt.exp0.tif\n",
            "Stripped 1 unrenderable words\n",
            "Rendered page 2 to file /tmp/eng-2022-03-26.f32/eng.Rock_Salt.exp0.tif\n",
            "Stripped 1 unrenderable words\n",
            "Rendered page 3 to file /tmp/eng-2022-03-26.f32/eng.Rock_Salt.exp0.tif\n",
            "Rendered page 4 to file /tmp/eng-2022-03-26.f32/eng.Rock_Salt.exp0.tif\n",
            "Stripped 2 unrenderable words\n",
            "Rendered page 5 to file /tmp/eng-2022-03-26.f32/eng.Rock_Salt.exp0.tif\n",
            "Rendered page 6 to file /tmp/eng-2022-03-26.f32/eng.Rock_Salt.exp0.tif\n",
            "Stripped 2 unrenderable words\n",
            "Rendered page 7 to file /tmp/eng-2022-03-26.f32/eng.Rock_Salt.exp0.tif\n",
            "Rendered page 8 to file /tmp/eng-2022-03-26.f32/eng.Rock_Salt.exp0.tif\n",
            "Rendered page 9 to file /tmp/eng-2022-03-26.f32/eng.Rock_Salt.exp0.tif\n",
            "\n",
            "=== Phase UP: Generating unicharset and unichar properties files ===\n",
            "[Sat Mar 26 17:12:28 UTC 2022] /usr/bin/unicharset_extractor --output_unicharset /tmp/eng-2022-03-26.f32/eng.unicharset --norm_mode 1 /tmp/eng-2022-03-26.f32/eng.Rock_Salt.exp0.box\n",
            "Extracting unicharset from box file /tmp/eng-2022-03-26.f32/eng.Rock_Salt.exp0.box\n",
            "Other case É of é is not in unicharset\n",
            "Wrote unicharset file /tmp/eng-2022-03-26.f32/eng.unicharset\n",
            "[Sat Mar 26 17:12:28 UTC 2022] /usr/bin/set_unicharset_properties -U /tmp/eng-2022-03-26.f32/eng.unicharset -O /tmp/eng-2022-03-26.f32/eng.unicharset -X /tmp/eng-2022-03-26.f32/eng.xheights --script_dir=/content/drive/MyDrive/langdata_lstm\n",
            "Loaded unicharset of size 111 from file /tmp/eng-2022-03-26.f32/eng.unicharset\n",
            "Setting unichar properties\n",
            "Other case É of é is not in unicharset\n",
            "Setting script properties\n",
            "Warning: properties incomplete for index 77 = ~\n",
            "Writing unicharset to file /tmp/eng-2022-03-26.f32/eng.unicharset\n",
            "\n",
            "=== Phase E: Generating lstmf files ===\n",
            "Using TESSDATA_PREFIX=/content/drive/MyDrive/tesseract/tessdata\n",
            "[Sat Mar 26 17:12:28 UTC 2022] /usr/bin/tesseract /tmp/eng-2022-03-26.f32/eng.Rock_Salt.exp0.tif /tmp/eng-2022-03-26.f32/eng.Rock_Salt.exp0 --psm 6 lstm.train\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Page 1\n",
            "Page 2\n",
            "Loaded 30/30 pages (1-30) of document /tmp/eng-2022-03-26.f32/eng.Rock_Salt.exp0.lstmf\n",
            "Page 3\n",
            "Loaded 60/60 pages (1-60) of document /tmp/eng-2022-03-26.f32/eng.Rock_Salt.exp0.lstmf\n",
            "Page 4\n",
            "Loaded 90/90 pages (1-90) of document /tmp/eng-2022-03-26.f32/eng.Rock_Salt.exp0.lstmf\n",
            "Page 5\n",
            "Loaded 120/120 pages (1-120) of document /tmp/eng-2022-03-26.f32/eng.Rock_Salt.exp0.lstmf\n",
            "Page 6\n",
            "Loaded 150/150 pages (1-150) of document /tmp/eng-2022-03-26.f32/eng.Rock_Salt.exp0.lstmf\n",
            "Page 7\n",
            "Loaded 180/180 pages (1-180) of document /tmp/eng-2022-03-26.f32/eng.Rock_Salt.exp0.lstmf\n",
            "Page 8\n",
            "Loaded 210/210 pages (1-210) of document /tmp/eng-2022-03-26.f32/eng.Rock_Salt.exp0.lstmf\n",
            "Page 9\n",
            "Loaded 240/240 pages (1-240) of document /tmp/eng-2022-03-26.f32/eng.Rock_Salt.exp0.lstmf\n",
            "Page 10\n",
            "Loaded 270/270 pages (1-270) of document /tmp/eng-2022-03-26.f32/eng.Rock_Salt.exp0.lstmf\n",
            "\n",
            "=== Constructing LSTM training data ===\n",
            "[Sat Mar 26 17:12:33 UTC 2022] /usr/bin/combine_lang_model --input_unicharset /tmp/eng-2022-03-26.f32/eng.unicharset --script_dir /content/drive/MyDrive/langdata_lstm --words /content/drive/MyDrive/langdata_lstm/eng/eng.wordlist --numbers /content/drive/MyDrive/langdata_lstm/eng/eng.numbers --puncs /content/drive/MyDrive/langdata_lstm/eng/eng.punc --output_dir train --lang eng\n",
            "Loaded unicharset of size 111 from file /tmp/eng-2022-03-26.f32/eng.unicharset\n",
            "Setting unichar properties\n",
            "Other case É of é is not in unicharset\n",
            "Setting script properties\n",
            "Warning: properties incomplete for index 77 = ~\n",
            "Config file is optional, continuing...\n",
            "Failed to read data from: /content/drive/MyDrive/langdata_lstm/eng/eng.config\n",
            "Null char=2\n",
            "Reducing Trie to SquishedDawg\n",
            "Reducing Trie to SquishedDawg\n",
            "Reducing Trie to SquishedDawg\n",
            "\n",
            "=== Saving box/tiff pairs for training data ===\n",
            "Moving /tmp/eng-2022-03-26.f32/eng.Rock_Salt.exp0.box to train\n",
            "Moving /tmp/eng-2022-03-26.f32/eng.Rock_Salt.exp0.tif to train\n",
            "\n",
            "=== Moving lstmf files for training data ===\n",
            "Moving /tmp/eng-2022-03-26.f32/eng.Rock_Salt.exp0.lstmf to train\n",
            "\n",
            "Created starter traineddata for LSTM training of language 'eng'\n",
            "\n",
            "\n",
            "Run 'lstmtraining' command to continue LSTM training for language 'eng'\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Beyzv0w4mdeA"
      },
      "source": [
        "#**#9 FINETUNE**\n",
        "\n",
        "**Trained data will be inside 'Output' folder**\n",
        "\n",
        "\n",
        "\n",
        "Change Max Iteration as per your need. The default here is 200. Increase this value to get less error."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZddishLny8Qt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f30ef696-acec-443e-97c7-9dc7e43d82c7"
      },
      "source": [
        "%%shell\n",
        "\n",
        "rm -rf output/* \n",
        "OMP_THREAD_LIMIT=16 lstmtraining \\\n",
        "\t--continue_from eng.lstm \\\n",
        "\t--model_output output/font_name \\\n",
        "\t--traineddata /content/drive/MyDrive/tesseract/tessdata/eng.traineddata \\\n",
        "\t--train_listfile train/eng.training_files.txt \\\n",
        "\t--max_iterations 400"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded file eng.lstm, unpacking...\n",
            "Warning: LSTMTrainer deserialized an LSTMRecognizer!\n",
            "Continuing from eng.lstm\n",
            "Loaded 300/300 pages (1-300) of document train/eng.Rock_Salt.exp0.lstmf\n",
            "2 Percent improvement time=100, best error was 100 @ 0\n",
            "At iteration 100/100/100, Mean rms=2.22%, delta=7.224%, char train=22.291%, word train=51.379%, skip ratio=0%,  New best char error = 22.291 wrote best model:output/font_name22.291_100.checkpoint wrote checkpoint.\n",
            "\n",
            "2 Percent improvement time=97, best error was 22.291 @ 100\n",
            "At iteration 197/200/200, Mean rms=1.797%, delta=4.919%, char train=15.522%, word train=39.008%, skip ratio=0%,  New best char error = 15.522 wrote best model:output/font_name15.522_197.checkpoint wrote checkpoint.\n",
            "\n",
            "2 Percent improvement time=91, best error was 15.522 @ 197\n",
            "At iteration 288/300/300, Mean rms=1.582%, delta=3.926%, char train=12.447%, word train=32.793%, skip ratio=0%,  New best char error = 12.447 wrote best model:output/font_name12.447_288.checkpoint wrote checkpoint.\n",
            "\n",
            "2 Percent improvement time=73, best error was 12.447 @ 288\n",
            "At iteration 361/400/400, Mean rms=1.404%, delta=3.219%, char train=10.278%, word train=27.752%, skip ratio=0%,  New best char error = 10.278 wrote best model:output/font_name10.278_361.checkpoint wrote checkpoint.\n",
            "\n",
            "Finished! Error rate = 10.278\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_gREJArnCl2"
      },
      "source": [
        "#**#10 GET TRAINED DATA**\n",
        "\n",
        "This command will create trained data from fontname.checkpoint. <br><br>\n",
        "This will be inside Output folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wPmBN9IM7Fx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c238ae6-e0fc-4cd6-be7b-6e389a02e500"
      },
      "source": [
        "%%shell\n",
        "\n",
        "lstmtraining --stop_training \\\n",
        "\t--continue_from output/font_name_checkpoint \\\n",
        "\t--traineddata /content/drive/MyDrive/tesseract/tessdata/eng.traineddata \\\n",
        "\t--model_output output/font_name.traineddata"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded file output/font_name_checkpoint, unpacking...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kk6u1hs4o2jE"
      },
      "source": [
        "#**HOW TO USE IT ?**\n",
        "\n",
        "\n",
        "---\n",
        "Download and paste the fontname.taineddata inside this location\n",
        "\n",
        "** FOR WINDOWS :**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "C:\\Program Files\\Tesseract-OCR\\tessdata\n",
        "\n",
        "**FIRE THIS IN COMMAND LINE IN COMMAND PROMPT**\n",
        "\n",
        "---\n",
        "*tesseract.exe imagename textfile -l fontname*\n",
        "\n",
        "***example : ***: \n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "*tesseract.exe image.jpg text.txt -l fontname*\n",
        "\n",
        "\n"
      ]
    }
  ]
}